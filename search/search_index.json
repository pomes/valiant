{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction Welcome! Valiant's main purpose is to provide an auditing tool for Python-based software development projects. The goal is to provide a tool that allows for easy review of software dependencies and aid in determining areas of risk for your project. Please check out the GitHub project site to dive into the codebase or raise/review issues. Features The following Valiant functionality works towards the project goals: Review a Python package using the valiant report command Prepare a bill of materials for all project dependencies using the valiant audit command Provide a variety of reporting plugins that will help in examining dependencies from different angles Valiant provides text- and JSON-based output options so the results can be either read on-screen (command line) or provided to a reporting database. Preparing the JSON output could be a useful part of your CI/CD process and interact with policy tools. Be mindful that Valiant is very new and under active development. There's a lot to be done and you must review all reports with a healthy analysis mindset. You should also be mindful that Valiant isn't judging a project to be good or bad - it's just trying to raise information that can help you assess risk. Terminology Just so we're all on the same page: Report provider : A \"plugin\" that reviews the package information for items of interest. For example, the safety report provider uses the safety package to check for known security vulnerabilties. Finding : An individual item of interest determined by a report provider Report : Provides an outline of a package and combines the findings from one or more report provider(s) Audit : Prepares a set of reports for a project's dependencies Quickstart Make sure you have a Python 3.8 environment ready to go and then: pip install valiant valiant about valiant report django 3.0.4 See the Walkthrough for more in-depth details.","title":"Introduction"},{"location":"#introduction","text":"Welcome! Valiant's main purpose is to provide an auditing tool for Python-based software development projects. The goal is to provide a tool that allows for easy review of software dependencies and aid in determining areas of risk for your project. Please check out the GitHub project site to dive into the codebase or raise/review issues.","title":"Introduction"},{"location":"#features","text":"The following Valiant functionality works towards the project goals: Review a Python package using the valiant report command Prepare a bill of materials for all project dependencies using the valiant audit command Provide a variety of reporting plugins that will help in examining dependencies from different angles Valiant provides text- and JSON-based output options so the results can be either read on-screen (command line) or provided to a reporting database. Preparing the JSON output could be a useful part of your CI/CD process and interact with policy tools. Be mindful that Valiant is very new and under active development. There's a lot to be done and you must review all reports with a healthy analysis mindset. You should also be mindful that Valiant isn't judging a project to be good or bad - it's just trying to raise information that can help you assess risk.","title":"Features"},{"location":"#terminology","text":"Just so we're all on the same page: Report provider : A \"plugin\" that reviews the package information for items of interest. For example, the safety report provider uses the safety package to check for known security vulnerabilties. Finding : An individual item of interest determined by a report provider Report : Provides an outline of a package and combines the findings from one or more report provider(s) Audit : Prepares a set of reports for a project's dependencies","title":"Terminology"},{"location":"#quickstart","text":"Make sure you have a Python 3.8 environment ready to go and then: pip install valiant valiant about valiant report django 3.0.4 See the Walkthrough for more in-depth details.","title":"Quickstart"},{"location":"cli/","text":"CLI Get started with the Valiant command line tool by just typing: valiant You'll get the full help text including a list of available commands. To get help on a specific command just run valiant help <command> : valiant help report Shell completions A completion script can be generated for several shells. Check out the following for details: valiant completions --help","title":"Commands"},{"location":"cli/#cli","text":"Get started with the Valiant command line tool by just typing: valiant You'll get the full help text including a list of available commands. To get help on a specific command just run valiant help <command> : valiant help report","title":"CLI"},{"location":"cli/#shell-completions","text":"A completion script can be generated for several shells. Check out the following for details: valiant completions --help","title":"Shell completions"},{"location":"configuration/","text":"Configuration Version 0.1.0 It's still very early days and Valiant isn't configurable. You can check the settings with: valiant config This will display the current configuration: cache_dir: /home/fred/.cache/valiant/0.1.0 config_dir: /home/fred/.config/valiant/0.1.0 default_repository_name: pypi repositories: pypi reports: basic,spdx,safety If you check the config_dir you'll see that Valiant is putting its logs in there. Notes You'll also notice that wherever you run the valiant command you'll see a file named valiant-0.1.0-requests-cache.sqlite has been created. This is a cache for web requests and helps both speed up Valiant as well as reduce load on repository servers. Track any update to this in Issue #4 . Version 0.2.0 Configuration has been improved under version 0.2.0 - and will benefit from real-world testing. This version will allow you to load configuration from multiple sources, including from a config file passed via the command line. Valiant configuration uses the TOML format. The easiest way to start a custom configuration is to run the following: valiant config --out toml This will provide a base config file that you can start editing. The example config below is a useful start: [tool.valiant] configuration_dir = \"/etc/valiant\" cache_dir = \"/tmp/valiant/cache\" log_dir = \"/tmp/valiant/log\" default_reports = [ \"basic\" ] [tool.valiant.requests_cache] file = \"$cache_dir/valiant-0.2.0-requests-cache\" backend = \"sqlite\" expire_after = 86400 I can save the config into a file named test.toml and use the following command: poetry run valiant config --config test.toml -o toml Placeholders You'll note the $cache_dir placeholder in the file setting for requests-cache . A very limited set of placeholders are available for the following settings: [tool.valiant.requests_cache] - file : The location of the requests cache. Note that you don't include the file extension here. The following placeholders will work and are based on the associated config setting: configuration_dir cache_dir log_dir Configuring logs Who doesn't love configuring logs? Valiant makes use of structlog to provide logging. If you need a custom logging setup, you first set up a logging configuration file - the one below just spits out to the command line (stdout): [loggers] keys=root [handlers] keys=consoleHandler [formatters] keys=simpleFormatter [logger_root] level=INFO handlers=consoleHandler [handler_consoleHandler] class=StreamHandler level=INFO formatter=simpleFormatter args=(sys.stdout,) [formatter_simpleFormatter] format=%(message)s datefmt= Then, in your Valiant config file, set the logging_configuration_file entry to the location of your logging config file: [tool.valiant] logging_configuration_file = \"/etc/valiant/logging.conf\" The loading process Configuration can be loaded from a number of places. Before we start please note that the configuration_dir setting doesn't indicate a location for Valiant to look for its own configuration. Instead, it could be used by plugins. If you need to specify a Valiant configuration file, please use the --config option in the command line. To start with, run the config command as follows: poetry run valiant config -v You'll see something along the following lines: configuration_dir: /home/fred/.config/valiant/0.2.0 cache_dir: /home/fred/.cache/valiant/0.2.0 log_dir: /home/fred/.cache/valiant/0.2.0/log default_repository: pypi repositories: pypi reports : {'basic', 'spdx', 'safety'} metadata: {'build_results': {'dictionary': 'Read', '/etc/xdg/xdg-cinnamon/valiant/0.2.0/config.toml': 'Not_Read', '/home/fred/.config/valiant/0.2.0/config.toml': 'Not_Read', '/home/fred/my_project/pyproject.toml': 'Read'}} The metadata section illustrates how Valiant is loading its configuration: First of all, a default config is read (noted as dictionary ) Then a site-level config.toml is checked - in this example, Not_Read highlights that no file was found. Then the user-level config.toml file is read, if it exists Finally, if the current directory has a pyproject.toml file then it will be read (not shown) If I passed in a configuration file using the --config option this will be read last Note: The AppDirs package is used to determine appropriate directory locations - check out their doco for the rationale behind the selected directories. Importantly, each step can replace settings made in an earlier step. This means that, ultimately, the file passed in with the --config option will gazump earlier settings.","title":"Configuration"},{"location":"configuration/#configuration","text":"","title":"Configuration"},{"location":"configuration/#version-010","text":"It's still very early days and Valiant isn't configurable. You can check the settings with: valiant config This will display the current configuration: cache_dir: /home/fred/.cache/valiant/0.1.0 config_dir: /home/fred/.config/valiant/0.1.0 default_repository_name: pypi repositories: pypi reports: basic,spdx,safety If you check the config_dir you'll see that Valiant is putting its logs in there.","title":"Version 0.1.0"},{"location":"configuration/#notes","text":"You'll also notice that wherever you run the valiant command you'll see a file named valiant-0.1.0-requests-cache.sqlite has been created. This is a cache for web requests and helps both speed up Valiant as well as reduce load on repository servers. Track any update to this in Issue #4 .","title":"Notes"},{"location":"configuration/#version-020","text":"Configuration has been improved under version 0.2.0 - and will benefit from real-world testing. This version will allow you to load configuration from multiple sources, including from a config file passed via the command line. Valiant configuration uses the TOML format. The easiest way to start a custom configuration is to run the following: valiant config --out toml This will provide a base config file that you can start editing. The example config below is a useful start: [tool.valiant] configuration_dir = \"/etc/valiant\" cache_dir = \"/tmp/valiant/cache\" log_dir = \"/tmp/valiant/log\" default_reports = [ \"basic\" ] [tool.valiant.requests_cache] file = \"$cache_dir/valiant-0.2.0-requests-cache\" backend = \"sqlite\" expire_after = 86400 I can save the config into a file named test.toml and use the following command: poetry run valiant config --config test.toml -o toml","title":"Version 0.2.0"},{"location":"configuration/#placeholders","text":"You'll note the $cache_dir placeholder in the file setting for requests-cache . A very limited set of placeholders are available for the following settings: [tool.valiant.requests_cache] - file : The location of the requests cache. Note that you don't include the file extension here. The following placeholders will work and are based on the associated config setting: configuration_dir cache_dir log_dir","title":"Placeholders"},{"location":"configuration/#configuring-logs","text":"Who doesn't love configuring logs? Valiant makes use of structlog to provide logging. If you need a custom logging setup, you first set up a logging configuration file - the one below just spits out to the command line (stdout): [loggers] keys=root [handlers] keys=consoleHandler [formatters] keys=simpleFormatter [logger_root] level=INFO handlers=consoleHandler [handler_consoleHandler] class=StreamHandler level=INFO formatter=simpleFormatter args=(sys.stdout,) [formatter_simpleFormatter] format=%(message)s datefmt= Then, in your Valiant config file, set the logging_configuration_file entry to the location of your logging config file: [tool.valiant] logging_configuration_file = \"/etc/valiant/logging.conf\"","title":"Configuring logs"},{"location":"configuration/#the-loading-process","text":"Configuration can be loaded from a number of places. Before we start please note that the configuration_dir setting doesn't indicate a location for Valiant to look for its own configuration. Instead, it could be used by plugins. If you need to specify a Valiant configuration file, please use the --config option in the command line. To start with, run the config command as follows: poetry run valiant config -v You'll see something along the following lines: configuration_dir: /home/fred/.config/valiant/0.2.0 cache_dir: /home/fred/.cache/valiant/0.2.0 log_dir: /home/fred/.cache/valiant/0.2.0/log default_repository: pypi repositories: pypi reports : {'basic', 'spdx', 'safety'} metadata: {'build_results': {'dictionary': 'Read', '/etc/xdg/xdg-cinnamon/valiant/0.2.0/config.toml': 'Not_Read', '/home/fred/.config/valiant/0.2.0/config.toml': 'Not_Read', '/home/fred/my_project/pyproject.toml': 'Read'}} The metadata section illustrates how Valiant is loading its configuration: First of all, a default config is read (noted as dictionary ) Then a site-level config.toml is checked - in this example, Not_Read highlights that no file was found. Then the user-level config.toml file is read, if it exists Finally, if the current directory has a pyproject.toml file then it will be read (not shown) If I passed in a configuration file using the --config option this will be read last Note: The AppDirs package is used to determine appropriate directory locations - check out their doco for the rationale behind the selected directories. Importantly, each step can replace settings made in an earlier step. This means that, ultimately, the file passed in with the --config option will gazump earlier settings.","title":"The loading process"},{"location":"limitations/","text":"Limitations It's new! ...and can be improved! Only packages in the central PyPI repo can be queried Overcome Fixed in 0.2.0 : The report providers are currently built-in. The ultimate goal is to provide a Flake8-style plugin model The caching database doesn't get stored in the cache directory - track this issue","title":"Limitations"},{"location":"limitations/#limitations","text":"It's new! ...and can be improved! Only packages in the central PyPI repo can be queried","title":"Limitations"},{"location":"limitations/#overcome","text":"Fixed in 0.2.0 : The report providers are currently built-in. The ultimate goal is to provide a Flake8-style plugin model The caching database doesn't get stored in the cache directory - track this issue","title":"Overcome"},{"location":"plugins/","text":"Plugins As of version 0.2.0 Valiant report providers are now plugins. Valiant uses a plugin approach based on Flake8's . This allows third-parties to provide Valiant plugins that will help users in auditing their dependencies. Using report plugins You can see which report plugins are available by running valiant config and check the Loaded report plugins line: Loaded report plugins: basic:0.1, demo:0.1, safety:1.8.7, localdemo:0.1, spdx:0.1 The reports line will tell you which reports are run by default: reports: {'safety', 'basic', 'spdx'} The default reports can be configured - see Configuration . Write a plugin There are two approaches to writing a plugin: Using package discovery provided by Setuptools. You just need to provide one or more entry points in your package. Using local scripts Implementing The demo report plugin is provided as a template from which you can build your own report plugin. The code for demo is reproduced below: \"\"\"Demonstrator plugin.\"\"\" from pathlib import Path from valiant.plugins.reports import ( BaseReportPlugin, Finding, FindingCategory, FindingLevel, PackageMetadata, Report, get_logger, ) log = get_logger() class DemoReportPlugin(BaseReportPlugin): \"\"\"A sample reporting plugin.\"\"\" name = \"demo\" vendor = \"Valiant\" display_name = \"Demo\" version = \"0.1\" url = \"\" @classmethod def prepare_report( cls, package_metadata: PackageMetadata, configuration_dir: Path ) -> Report: \"\"\"Run the report. Args: package_metadata: The package information configuration_dir: A directory for locating config Returns: A report with (perhaps) a finding or two. \"\"\" report = Report(cls.report_provider_details()) log.info( \"The demo plugin was called\", package_name=package_metadata.name, package_version=package_metadata.version, ) report.add_finding( Finding( coordinates=package_metadata.coordinates, id=\"DEMO001\", title=\"Demo finding\", category=FindingCategory.PROJECT.value, level=FindingLevel.INFO, message=\"This is a demo finding\", data={\"value\": \"demo\"}, url=\"http://www.example.com\", ) ) return report The main work items you need to undertake are: Create a class that extends BaseReportPlugin Set your plugin class values ( name , version , vendor , display_name , url ) Overload the prepare_report class method Access your plugin either via the entry point or local approach The prepare_report class method signature is as follows: @classmethod def prepare_report( cls, package_metadata: PackageMetadata, configuration_dir: Path ) -> Report Valiant will pass your plugin: An instance of PackageMetadata for your plugin to report on. A configuration_dir that you might use in order to get configuration for your plugin. If your plugin/app has an established configuration approach you can just ignore configuration_dir . Your implementation will work its magic and return an instance of Report that Valiant will add to the set of reports to be provided to the user. Creating a report is straight-forward, just use the following: report = Report(cls.report_provider_details()) This will get your plugin info together (using report_provider_details ). From there you start adding Finding s . A Finding is an item that your plugin determines to be a useful information item. This could be a general bit of information, a security concern, details about project popularity - the focus is really on anything that can help the user in auditing their dependencies. You can take a look at the built-in report plugins to see how they're preparing findings. Preparing a single finding is a matter of drawing together some details: report.add_finding( Finding( coordinates=package_metadata.coordinates, id=\"DEMO001\", title=\"Demo finding\", category=FindingCategory.PROJECT.value, level=FindingLevel.INFO, message=\"This is a demo finding\", data={\"value\": \"demo\"}, url=\"http://www.example.com\", ) ) Breaking this down with some explanation: coordinates=package_metadata.coordinates : Just use this line verbatim id=\"DEMO001\" : Your plugin should produce an identifier per finding type. The format for id is the uppercase name of the plugin plus a 3-digit number. title=\"Demo finding\" : An eye-cathing title for the finding category=FindingCategory.PROJECT.value : An open category string. Use anything that you feel is a useful category but check the FindingCategory enum to see if one already exists. level=FindingLevel.INFO : One of priority , warning , info - use the FindingLevel enum to help you. message=\"This is a demo finding\" : A summary of the finding. data={\"value\": \"demo\"} | : A Mapping that provides useful data about the finding. Use JSON-convertible types (e.g. str and int ) in the Mapping to allow for different output formats. url=\"http://www.example.com\" : A handy URL that will give further information about the finding. Entry points As Valiant uses the Poetry packaging tool, we can look at its own pyproject.toml and see how the report plugins are flagged as entry points: [tool.poetry.plugins.\"valiant.report\"] \"demo\" = \"valiant.plugins.reports.demo:DemoReportPlugin\" \"basic\" = \"valiant.plugins.reports.basic:BasicReportPlugin\" \"spdx\" = \"valiant.plugins.reports.spdx:SpdxLicenseReportPlugin\" \"safety\" = \"valiant.plugins.reports.safety:SafetyReportPlugin\" Valiant will look for all declared valiant.report entry points. Any package you've installed (e.g. via pip ) that declares such an entry point can then be a report provider for your reports/audits. Local plugins You don't need to package up your plugin to use it - this is handy if it's just for a project your team is working on. You can add the following lines to your pyproject.toml or any of your configuration files to start using local plugins. [tool.valiant.local-plugins] paths = [\"./tests/plugins\"] [tool.valiant.local-plugins.\"valiant.report\"] localdemo = \"reports.localdemo:LocalDemoReportPlugin\" The paths item is a list of paths in which Valiant will seek out your plugin. The [tool.valiant.local-plugins.\"valiant.report\"] section contains one or more report plugins. Each plugin is described using <name> = \"<entry point>\" . The example above ( localdemo = \"reports.localdemo:LocalDemoReportPlugin\" ) designates a report provider named localdemo with an entry point being a class that extends BaseReportPlugin . You can review the code for this plugin at: LocalDemoReportPlugin","title":"Plugins"},{"location":"plugins/#plugins","text":"As of version 0.2.0 Valiant report providers are now plugins. Valiant uses a plugin approach based on Flake8's . This allows third-parties to provide Valiant plugins that will help users in auditing their dependencies.","title":"Plugins"},{"location":"plugins/#using-report-plugins","text":"You can see which report plugins are available by running valiant config and check the Loaded report plugins line: Loaded report plugins: basic:0.1, demo:0.1, safety:1.8.7, localdemo:0.1, spdx:0.1 The reports line will tell you which reports are run by default: reports: {'safety', 'basic', 'spdx'} The default reports can be configured - see Configuration .","title":"Using report plugins"},{"location":"plugins/#write-a-plugin","text":"There are two approaches to writing a plugin: Using package discovery provided by Setuptools. You just need to provide one or more entry points in your package. Using local scripts","title":"Write a plugin"},{"location":"plugins/#implementing","text":"The demo report plugin is provided as a template from which you can build your own report plugin. The code for demo is reproduced below: \"\"\"Demonstrator plugin.\"\"\" from pathlib import Path from valiant.plugins.reports import ( BaseReportPlugin, Finding, FindingCategory, FindingLevel, PackageMetadata, Report, get_logger, ) log = get_logger() class DemoReportPlugin(BaseReportPlugin): \"\"\"A sample reporting plugin.\"\"\" name = \"demo\" vendor = \"Valiant\" display_name = \"Demo\" version = \"0.1\" url = \"\" @classmethod def prepare_report( cls, package_metadata: PackageMetadata, configuration_dir: Path ) -> Report: \"\"\"Run the report. Args: package_metadata: The package information configuration_dir: A directory for locating config Returns: A report with (perhaps) a finding or two. \"\"\" report = Report(cls.report_provider_details()) log.info( \"The demo plugin was called\", package_name=package_metadata.name, package_version=package_metadata.version, ) report.add_finding( Finding( coordinates=package_metadata.coordinates, id=\"DEMO001\", title=\"Demo finding\", category=FindingCategory.PROJECT.value, level=FindingLevel.INFO, message=\"This is a demo finding\", data={\"value\": \"demo\"}, url=\"http://www.example.com\", ) ) return report The main work items you need to undertake are: Create a class that extends BaseReportPlugin Set your plugin class values ( name , version , vendor , display_name , url ) Overload the prepare_report class method Access your plugin either via the entry point or local approach The prepare_report class method signature is as follows: @classmethod def prepare_report( cls, package_metadata: PackageMetadata, configuration_dir: Path ) -> Report Valiant will pass your plugin: An instance of PackageMetadata for your plugin to report on. A configuration_dir that you might use in order to get configuration for your plugin. If your plugin/app has an established configuration approach you can just ignore configuration_dir . Your implementation will work its magic and return an instance of Report that Valiant will add to the set of reports to be provided to the user. Creating a report is straight-forward, just use the following: report = Report(cls.report_provider_details()) This will get your plugin info together (using report_provider_details ). From there you start adding Finding s . A Finding is an item that your plugin determines to be a useful information item. This could be a general bit of information, a security concern, details about project popularity - the focus is really on anything that can help the user in auditing their dependencies. You can take a look at the built-in report plugins to see how they're preparing findings. Preparing a single finding is a matter of drawing together some details: report.add_finding( Finding( coordinates=package_metadata.coordinates, id=\"DEMO001\", title=\"Demo finding\", category=FindingCategory.PROJECT.value, level=FindingLevel.INFO, message=\"This is a demo finding\", data={\"value\": \"demo\"}, url=\"http://www.example.com\", ) ) Breaking this down with some explanation: coordinates=package_metadata.coordinates : Just use this line verbatim id=\"DEMO001\" : Your plugin should produce an identifier per finding type. The format for id is the uppercase name of the plugin plus a 3-digit number. title=\"Demo finding\" : An eye-cathing title for the finding category=FindingCategory.PROJECT.value : An open category string. Use anything that you feel is a useful category but check the FindingCategory enum to see if one already exists. level=FindingLevel.INFO : One of priority , warning , info - use the FindingLevel enum to help you. message=\"This is a demo finding\" : A summary of the finding. data={\"value\": \"demo\"} | : A Mapping that provides useful data about the finding. Use JSON-convertible types (e.g. str and int ) in the Mapping to allow for different output formats. url=\"http://www.example.com\" : A handy URL that will give further information about the finding.","title":"Implementing"},{"location":"plugins/#entry-points","text":"As Valiant uses the Poetry packaging tool, we can look at its own pyproject.toml and see how the report plugins are flagged as entry points: [tool.poetry.plugins.\"valiant.report\"] \"demo\" = \"valiant.plugins.reports.demo:DemoReportPlugin\" \"basic\" = \"valiant.plugins.reports.basic:BasicReportPlugin\" \"spdx\" = \"valiant.plugins.reports.spdx:SpdxLicenseReportPlugin\" \"safety\" = \"valiant.plugins.reports.safety:SafetyReportPlugin\" Valiant will look for all declared valiant.report entry points. Any package you've installed (e.g. via pip ) that declares such an entry point can then be a report provider for your reports/audits.","title":"Entry points"},{"location":"plugins/#local-plugins","text":"You don't need to package up your plugin to use it - this is handy if it's just for a project your team is working on. You can add the following lines to your pyproject.toml or any of your configuration files to start using local plugins. [tool.valiant.local-plugins] paths = [\"./tests/plugins\"] [tool.valiant.local-plugins.\"valiant.report\"] localdemo = \"reports.localdemo:LocalDemoReportPlugin\" The paths item is a list of paths in which Valiant will seek out your plugin. The [tool.valiant.local-plugins.\"valiant.report\"] section contains one or more report plugins. Each plugin is described using <name> = \"<entry point>\" . The example above ( localdemo = \"reports.localdemo:LocalDemoReportPlugin\" ) designates a report provider named localdemo with an entry point being a class that extends BaseReportPlugin . You can review the code for this plugin at: LocalDemoReportPlugin","title":"Local plugins"},{"location":"providers/","text":"Report providers You can view a list of available report providers by running valiant config . You'll see them listed in the Loaded report plugins line: Loaded report plugins: basic:0.1, demo:0.1, safety:1.8.7, localdemo:0.1, spdx:0.1 Report providers are plugins and you can write your own - check out the Plugins page . basic See: README safety See: README spdx See: README","title":"Report providers"},{"location":"providers/#report-providers","text":"You can view a list of available report providers by running valiant config . You'll see them listed in the Loaded report plugins line: Loaded report plugins: basic:0.1, demo:0.1, safety:1.8.7, localdemo:0.1, spdx:0.1 Report providers are plugins and you can write your own - check out the Plugins page .","title":"Report providers"},{"location":"providers/#basic","text":"See: README","title":"basic"},{"location":"providers/#safety","text":"See: README","title":"safety"},{"location":"providers/#spdx","text":"See: README","title":"spdx"},{"location":"walkthrough/","text":"Walkthrough Before you start, please remember that Valiant is brand new and still in a state of change/development. You should make sure that you use Valiant with this is mind. Install You need to be running Python 3.8 or higher. If you're not running 3.8, pyenv can make this very easy for you and I'd strongly recommend checking out their instructions. I'd also recommend using a virtual environment. The \"built in\" approach to this (once you have Python 3.8 installed) is to: python -m virtualenv --python 3.8 venv . venv/bin/activate python --version Hopefully you get something like Python 3.8.x . With that going you can now install Valiant: pip install valiant ...and check it's working: valiant about Containers Containers can be handy if you're just taking Valiant for a spin. Grab a copy of the Python 3.8 image: docker pull docker.io/python:3.8 Start it up: docker run --rm -it docker.io/python:3.8 /bin/bash Once in the container shell you can install Valiant and try it out: pip install valiant valiant about From the GitHub project pip install git+https://github.com/pomes/valiant.git It's a really good idea to do this type of thing in a virtual env! Poetry will help you out here and install Valiant as a dev dependency: poetry add -D git+https://github.com/pomes/valiant.git Configuration Please check out the Configuration page for details. Review a dependency Say you wanted to find out about a dependency. The report command will give you information about the project/release plus run some checks. Let's try it out: valiant report flask 1.1.1 You'll get the following output: Package metadata +-------------+----------------------------------------------------------------+ | Item | Value(s) | +=============+================================================================+ | Package | Flask | +-------------+----------------------------------------------------------------+ | Version | 1.1.1 | +-------------+----------------------------------------------------------------+ | Repository | https://pypi.org/pypi | +-------------+----------------------------------------------------------------+ | License | BSD-3-Clause | +-------------+----------------------------------------------------------------+ | Summary | A simple framework for building complex web applications. | +-------------+----------------------------------------------------------------+ | Resources | Project: https://palletsprojects.com/p/flask/ | | | Code: https://github.com/pallets/flask | | | Documentation: https://flask.palletsprojects.com/ | | | Issue tracker:: https://github.com/pallets/flask/issues | +-------------+----------------------------------------------------------------+ | Classifiers | Development Status :: 5 - Production/Stable | | | Environment :: Web Environment | | | Framework :: Flask | | | Intended Audience :: Developers | | | License :: OSI Approved :: BSD License | | | Operating System :: OS Independent | | | Programming Language :: Python | | | Programming Language :: Python :: 2 | | | Programming Language :: Python :: 2.7 | | | Programming Language :: Python :: 3 | | | Programming Language :: Python :: 3.5 | | | Programming Language :: Python :: 3.6 | | | Programming Language :: Python :: 3.7 | | | Topic :: Internet :: WWW/HTTP :: Dynamic Content | | | Topic :: Internet :: WWW/HTTP :: WSGI :: Application | | | Topic :: Software Development :: Libraries :: Application | | | Frameworks | | | Topic :: Software Development :: Libraries :: Python Modules | +-------------+----------------------------------------------------------------+ | Artifacts | bdist_wheel: https://files.pythonhosted.org/packages/9b/93/628 | | | 509b8d5dc749656a9641f4caf13540e2cdec85276964ff8f43bbb1d3b/Flas | | | k-1.1.1-py2.py3-none-any.whl | | | --- | | | sdist: https://files.pythonhosted.org/packages/2e/80/3726a729d | | | e758513fd3dbc64e93098eb009c49305a97c6751de55b20b694/Flask-1.1. | | | 1.tar.gz | +-------------+----------------------------------------------------------------+ Report: Basic [https://pypi.org/pypi :: Flask :: 1.1.1] No findings Report: SPDX License [https://pypi.org/pypi :: Flask :: 1.1.1] +----------+---------+----------+--------------------+--------------+ | Priority | ID | Category | Title | Message | +==========+=========+==========+====================+==============+ | info | SPDX001 | license | SPDX License found | BSD-3-Clause | +----------+---------+----------+--------------------+--------------+ Report: Safety [https://pypi.org/pypi :: Flask :: 1.1.1] No findings It all looks pretty good. Let's try another one: valiant report rdflib 4.2.2 This will yield some findings for us to consider: Package metadata +-------------+----------------------------------------------------------------+ | Item | Value(s) | +=============+================================================================+ | Package | rdflib | +-------------+----------------------------------------------------------------+ | Version | 4.2.2 | +-------------+----------------------------------------------------------------+ | Repository | https://pypi.org/pypi | +-------------+----------------------------------------------------------------+ | License | https://raw.github.com/RDFLib/rdflib/master/LICENSE | +-------------+----------------------------------------------------------------+ | Summary | RDFLib is a Python library for working with RDF, a simple yet | | | powerful language for representing information. | +-------------+----------------------------------------------------------------+ | Resources | Project: https://github.com/RDFLib/rdflib | | | Code: | | | Documentation: | | | Issue tracker:: | +-------------+----------------------------------------------------------------+ | Classifiers | License :: OSI Approved :: BSD License | | | Natural Language :: English | | | Operating System :: OS Independent | | | Programming Language :: Python | | | Programming Language :: Python :: 2 | | | Programming Language :: Python :: 2.6 | | | Programming Language :: Python :: 2.7 | | | Programming Language :: Python :: 3 | | | Programming Language :: Python :: 3.3 | | | Programming Language :: Python :: 3.4 | | | Programming Language :: Python :: 3.5 | | | Topic :: Software Development :: Libraries :: Python Modules | +-------------+----------------------------------------------------------------+ | Artifacts | bdist_wheel: https://files.pythonhosted.org/packages/3c/fe/630 | | | bacb652680f6d481b9febbb3e2c3869194a1a5fc3401a4a41195a2f8f/rdfl | | | ib-4.2.2-py3-none-any.whl | | | --- | | | sdist: https://files.pythonhosted.org/packages/c5/77/1fa0f4cff | | | d5faad496b1344ab665902bb2609f56e0fb19bcf80cff485da0/rdflib-4.2 | | | .2.tar.gz | +-------------+----------------------------------------------------------------+ Report: Basic [https://pypi.org/pypi :: rdflib :: 4.2.2] +----------+----------+----------+----------------------+----------------------+ | Priority | ID | Category | Title | Message | +==========+==========+==========+======================+======================+ | warning | BASIC003 | project | No link to codebase | The project doesn't | | | | | | provide a link to | | | | | | its codebase. | +----------+----------+----------+----------------------+----------------------+ | warning | BASIC004 | project | An artifact has not | A package of type | | | | | been signed | bdist_wheel has not | | | | | | been signed | +----------+----------+----------+----------------------+----------------------+ | warning | BASIC004 | project | An artifact has not | A package of type | | | | | been signed | sdist has not been | | | | | | signed | +----------+----------+----------+----------------------+----------------------+ Report: SPDX License [https://pypi.org/pypi :: rdflib :: 4.2.2] +----------+---------+----------+-----------------------+----------------------+ | Priority | ID | Category | Title | Message | +==========+=========+==========+=======================+======================+ | info | SPDX002 | license | SPDX License not | Could not map | | | | | found | licence https://raw. | | | | | | github.com/RDFLib/rd | | | | | | flib/master/LICENSE | | | | | | to an SPDX license | +----------+---------+----------+-----------------------+----------------------+ Report: Safety [https://pypi.org/pypi :: rdflib :: 4.2.2] +----------+-----------+----------+---------------------+----------------------+ | Priority | ID | Category | Title | Message | +==========+===========+==========+=====================+======================+ | priority | SAFETY001 | security | Vulnerability found | The CLI tools in | | | | | | RDFLib 4.2.2 can | | | | | | load Python modules | | | | | | from the current | | | | | | working directory, | | | | | | allowing code | | | | | | injection, because | | | | | | \"python -m\" looks in | | | | | | this directory, as | | | | | | demonstrated by | | | | | | rdf2dot. | +----------+-----------+----------+---------------------+----------------------+ Sometimes you just want the findings: valiant report rdflib 4.2.2 -s This will give us a quick table to check: +--------------+-----------+----------+----------+--------------+--------------+ | Package | ID | Level | Category | Title | Message | | Coordinates | | | | | | +==============+===========+==========+==========+==============+==============+ | https://pypi | BASIC003 | warning | project | No link to | The project | | .org/pypi :: | | | | codebase | doesn't | | rdflib :: | | | | | provide a | | 4.2.2 | | | | | link to its | | | | | | | codebase. | +--------------+-----------+----------+----------+--------------+--------------+ | https://pypi | BASIC004 | warning | project | An artifact | A package of | | .org/pypi :: | | | | has not been | type | | rdflib :: | | | | signed | bdist_wheel | | 4.2.2 | | | | | has not been | | | | | | | signed | +--------------+-----------+----------+----------+--------------+--------------+ | https://pypi | BASIC004 | warning | project | An artifact | A package of | | .org/pypi :: | | | | has not been | type sdist | | rdflib :: | | | | signed | has not been | | 4.2.2 | | | | | signed | +--------------+-----------+----------+----------+--------------+--------------+ | https://pypi | SPDX002 | info | license | SPDX License | Could not | | .org/pypi :: | | | | not found | map licence | | rdflib :: | | | | | https://raw. | | 4.2.2 | | | | | github.com/R | | | | | | | DFLib/rdflib | | | | | | | /master/LICE | | | | | | | NSE to an | | | | | | | SPDX license | +--------------+-----------+----------+----------+--------------+--------------+ | https://pypi | SAFETY001 | priority | security | Vulnerabilit | The CLI | | .org/pypi :: | | | | y found | tools in | | rdflib :: | | | | | RDFLib 4.2.2 | | 4.2.2 | | | | | can load | | | | | | | Python | | | | | | | modules from | | | | | | | the current | | | | | | | working | | | | | | | directory, | | | | | | | allowing | | | | | | | code | | | | | | | injection, | | | | | | | because | | | | | | | \"python -m\" | | | | | | | looks in | | | | | | | this | | | | | | | directory, | | | | | | | as | | | | | | | demonstrated | | | | | | | by rdf2dot. | +--------------+-----------+----------+----------+--------------+--------------+ You can run specific reports by listing them. In the command below I just ask for the report from the safety reporter: valiant report rdflib 4.2.2 safety -s For multiple reports, just use a comma separator: valiant report rdflib 4.2.2 safety,basic -s You can see the list of available reports by running the valiant config command. JSON reports You can get a copy of the report in JSON by setting the output: valiant report rdflib 4.2.2 -o json You can also produce a JSON-based findings report: valiant report rdflib 4.2.2 -s -o json As we saw in the test output examples, you can limit the reports you want: valiant report rdflib 4.2.2 safety -s -o json As a hint, it can be useful to pass the result to the handy jq tool : poetry run valiant report flask 1.1.1 -o json | jq This will give you something like: [ { \"id\": \"SAFETY001\", \"coordinates\": { \"name\": \"rdflib\", \"version\": \"4.2.2\", \"repository_url\": \"https://pypi.org/pypi\" }, \"level\": \"priority\", \"category\": \"security\", \"title\": \"Vulnerability found\", \"message\": \"The CLI tools in RDFLib 4.2.2 can load Python modules from the current working directory, allowing code injection, because \\\"python -m\\\" looks in this directory, as demonstrated by rdf2dot.\", \"data\": { \"name\": \"rdflib\", \"spec\": \"==4.2.2\", \"version\": \"4.2.2\", \"advisory\": \"The CLI tools in RDFLib 4.2.2 can load Python modules from the current working directory, allowing code injection, because \\\"python -m\\\" looks in this directory, as demonstrated by rdf2dot.\", \"vuln_id\": \"36882\" }, \"url\": \"https://github.com/pyupio/safety-db\" } ] Auditing a project An audit is essentially a review of multiple dependencies. Valiant uses a requirements file as input. Importantly, the packages listed in the requirements file must be pinned to a specific version. The example below illustrates how this looks: click==7.1.1 flask==1.1.1 isodate==0.6.0 itsdangerous==1.1.0 jinja2==2.11.1 markupsafe==1.1.1 numpy==1.18.2 pandas==1.0.3 pyparsing==2.4.6 python-dateutil==2.8.1 pytz==2019.3 rdflib==4.2.2 six==1.14.0 werkzeug==1.0.0 Thankfully, Poetry's export command makes this easy and we'll use this in the walk-through. Let's go through the steps of creating a small project and running an audit. First of all, create a directory for the test project: # Setup the project mkdir test-valiant cd test-valiant Make sure you're running Python 3.8 (or greater). I use pyenv and this makes it easy: pyenv local 3.8.2 Better still, create a virtualenv - see the instructions at the beginning of this page. Now we set up the Poetry project and add some dependencies: pip install poetry poetry init -n # Add some dependencies poetry add flask rdflib pandas requests It's now possible to export the pinned requirements file: # Export the requirements file poetry export --without-hashes --format requirements.txt --output requirements.txt You can now run an audit of your dependencies with: valiant audit requirements.txt This will pump out a lot of information for you to sift through! It's basically a set of reports - much like running the valiant report command for each package. If you just want to view the findings across all reports: valiant audit requirements.txt -s JSON audit reports As with the one-off report, you can get the audit in JSON format: poetry run valiant audit requirements.txt -o json The findings-only listing is also available: poetry run valiant audit requirements.txt -s -o json","title":"Walkthrough"},{"location":"walkthrough/#walkthrough","text":"Before you start, please remember that Valiant is brand new and still in a state of change/development. You should make sure that you use Valiant with this is mind.","title":"Walkthrough"},{"location":"walkthrough/#install","text":"You need to be running Python 3.8 or higher. If you're not running 3.8, pyenv can make this very easy for you and I'd strongly recommend checking out their instructions. I'd also recommend using a virtual environment. The \"built in\" approach to this (once you have Python 3.8 installed) is to: python -m virtualenv --python 3.8 venv . venv/bin/activate python --version Hopefully you get something like Python 3.8.x . With that going you can now install Valiant: pip install valiant ...and check it's working: valiant about","title":"Install"},{"location":"walkthrough/#containers","text":"Containers can be handy if you're just taking Valiant for a spin. Grab a copy of the Python 3.8 image: docker pull docker.io/python:3.8 Start it up: docker run --rm -it docker.io/python:3.8 /bin/bash Once in the container shell you can install Valiant and try it out: pip install valiant valiant about","title":"Containers"},{"location":"walkthrough/#from-the-github-project","text":"pip install git+https://github.com/pomes/valiant.git It's a really good idea to do this type of thing in a virtual env! Poetry will help you out here and install Valiant as a dev dependency: poetry add -D git+https://github.com/pomes/valiant.git","title":"From the GitHub project"},{"location":"walkthrough/#configuration","text":"Please check out the Configuration page for details.","title":"Configuration"},{"location":"walkthrough/#review-a-dependency","text":"Say you wanted to find out about a dependency. The report command will give you information about the project/release plus run some checks. Let's try it out: valiant report flask 1.1.1 You'll get the following output: Package metadata +-------------+----------------------------------------------------------------+ | Item | Value(s) | +=============+================================================================+ | Package | Flask | +-------------+----------------------------------------------------------------+ | Version | 1.1.1 | +-------------+----------------------------------------------------------------+ | Repository | https://pypi.org/pypi | +-------------+----------------------------------------------------------------+ | License | BSD-3-Clause | +-------------+----------------------------------------------------------------+ | Summary | A simple framework for building complex web applications. | +-------------+----------------------------------------------------------------+ | Resources | Project: https://palletsprojects.com/p/flask/ | | | Code: https://github.com/pallets/flask | | | Documentation: https://flask.palletsprojects.com/ | | | Issue tracker:: https://github.com/pallets/flask/issues | +-------------+----------------------------------------------------------------+ | Classifiers | Development Status :: 5 - Production/Stable | | | Environment :: Web Environment | | | Framework :: Flask | | | Intended Audience :: Developers | | | License :: OSI Approved :: BSD License | | | Operating System :: OS Independent | | | Programming Language :: Python | | | Programming Language :: Python :: 2 | | | Programming Language :: Python :: 2.7 | | | Programming Language :: Python :: 3 | | | Programming Language :: Python :: 3.5 | | | Programming Language :: Python :: 3.6 | | | Programming Language :: Python :: 3.7 | | | Topic :: Internet :: WWW/HTTP :: Dynamic Content | | | Topic :: Internet :: WWW/HTTP :: WSGI :: Application | | | Topic :: Software Development :: Libraries :: Application | | | Frameworks | | | Topic :: Software Development :: Libraries :: Python Modules | +-------------+----------------------------------------------------------------+ | Artifacts | bdist_wheel: https://files.pythonhosted.org/packages/9b/93/628 | | | 509b8d5dc749656a9641f4caf13540e2cdec85276964ff8f43bbb1d3b/Flas | | | k-1.1.1-py2.py3-none-any.whl | | | --- | | | sdist: https://files.pythonhosted.org/packages/2e/80/3726a729d | | | e758513fd3dbc64e93098eb009c49305a97c6751de55b20b694/Flask-1.1. | | | 1.tar.gz | +-------------+----------------------------------------------------------------+ Report: Basic [https://pypi.org/pypi :: Flask :: 1.1.1] No findings Report: SPDX License [https://pypi.org/pypi :: Flask :: 1.1.1] +----------+---------+----------+--------------------+--------------+ | Priority | ID | Category | Title | Message | +==========+=========+==========+====================+==============+ | info | SPDX001 | license | SPDX License found | BSD-3-Clause | +----------+---------+----------+--------------------+--------------+ Report: Safety [https://pypi.org/pypi :: Flask :: 1.1.1] No findings It all looks pretty good. Let's try another one: valiant report rdflib 4.2.2 This will yield some findings for us to consider: Package metadata +-------------+----------------------------------------------------------------+ | Item | Value(s) | +=============+================================================================+ | Package | rdflib | +-------------+----------------------------------------------------------------+ | Version | 4.2.2 | +-------------+----------------------------------------------------------------+ | Repository | https://pypi.org/pypi | +-------------+----------------------------------------------------------------+ | License | https://raw.github.com/RDFLib/rdflib/master/LICENSE | +-------------+----------------------------------------------------------------+ | Summary | RDFLib is a Python library for working with RDF, a simple yet | | | powerful language for representing information. | +-------------+----------------------------------------------------------------+ | Resources | Project: https://github.com/RDFLib/rdflib | | | Code: | | | Documentation: | | | Issue tracker:: | +-------------+----------------------------------------------------------------+ | Classifiers | License :: OSI Approved :: BSD License | | | Natural Language :: English | | | Operating System :: OS Independent | | | Programming Language :: Python | | | Programming Language :: Python :: 2 | | | Programming Language :: Python :: 2.6 | | | Programming Language :: Python :: 2.7 | | | Programming Language :: Python :: 3 | | | Programming Language :: Python :: 3.3 | | | Programming Language :: Python :: 3.4 | | | Programming Language :: Python :: 3.5 | | | Topic :: Software Development :: Libraries :: Python Modules | +-------------+----------------------------------------------------------------+ | Artifacts | bdist_wheel: https://files.pythonhosted.org/packages/3c/fe/630 | | | bacb652680f6d481b9febbb3e2c3869194a1a5fc3401a4a41195a2f8f/rdfl | | | ib-4.2.2-py3-none-any.whl | | | --- | | | sdist: https://files.pythonhosted.org/packages/c5/77/1fa0f4cff | | | d5faad496b1344ab665902bb2609f56e0fb19bcf80cff485da0/rdflib-4.2 | | | .2.tar.gz | +-------------+----------------------------------------------------------------+ Report: Basic [https://pypi.org/pypi :: rdflib :: 4.2.2] +----------+----------+----------+----------------------+----------------------+ | Priority | ID | Category | Title | Message | +==========+==========+==========+======================+======================+ | warning | BASIC003 | project | No link to codebase | The project doesn't | | | | | | provide a link to | | | | | | its codebase. | +----------+----------+----------+----------------------+----------------------+ | warning | BASIC004 | project | An artifact has not | A package of type | | | | | been signed | bdist_wheel has not | | | | | | been signed | +----------+----------+----------+----------------------+----------------------+ | warning | BASIC004 | project | An artifact has not | A package of type | | | | | been signed | sdist has not been | | | | | | signed | +----------+----------+----------+----------------------+----------------------+ Report: SPDX License [https://pypi.org/pypi :: rdflib :: 4.2.2] +----------+---------+----------+-----------------------+----------------------+ | Priority | ID | Category | Title | Message | +==========+=========+==========+=======================+======================+ | info | SPDX002 | license | SPDX License not | Could not map | | | | | found | licence https://raw. | | | | | | github.com/RDFLib/rd | | | | | | flib/master/LICENSE | | | | | | to an SPDX license | +----------+---------+----------+-----------------------+----------------------+ Report: Safety [https://pypi.org/pypi :: rdflib :: 4.2.2] +----------+-----------+----------+---------------------+----------------------+ | Priority | ID | Category | Title | Message | +==========+===========+==========+=====================+======================+ | priority | SAFETY001 | security | Vulnerability found | The CLI tools in | | | | | | RDFLib 4.2.2 can | | | | | | load Python modules | | | | | | from the current | | | | | | working directory, | | | | | | allowing code | | | | | | injection, because | | | | | | \"python -m\" looks in | | | | | | this directory, as | | | | | | demonstrated by | | | | | | rdf2dot. | +----------+-----------+----------+---------------------+----------------------+ Sometimes you just want the findings: valiant report rdflib 4.2.2 -s This will give us a quick table to check: +--------------+-----------+----------+----------+--------------+--------------+ | Package | ID | Level | Category | Title | Message | | Coordinates | | | | | | +==============+===========+==========+==========+==============+==============+ | https://pypi | BASIC003 | warning | project | No link to | The project | | .org/pypi :: | | | | codebase | doesn't | | rdflib :: | | | | | provide a | | 4.2.2 | | | | | link to its | | | | | | | codebase. | +--------------+-----------+----------+----------+--------------+--------------+ | https://pypi | BASIC004 | warning | project | An artifact | A package of | | .org/pypi :: | | | | has not been | type | | rdflib :: | | | | signed | bdist_wheel | | 4.2.2 | | | | | has not been | | | | | | | signed | +--------------+-----------+----------+----------+--------------+--------------+ | https://pypi | BASIC004 | warning | project | An artifact | A package of | | .org/pypi :: | | | | has not been | type sdist | | rdflib :: | | | | signed | has not been | | 4.2.2 | | | | | signed | +--------------+-----------+----------+----------+--------------+--------------+ | https://pypi | SPDX002 | info | license | SPDX License | Could not | | .org/pypi :: | | | | not found | map licence | | rdflib :: | | | | | https://raw. | | 4.2.2 | | | | | github.com/R | | | | | | | DFLib/rdflib | | | | | | | /master/LICE | | | | | | | NSE to an | | | | | | | SPDX license | +--------------+-----------+----------+----------+--------------+--------------+ | https://pypi | SAFETY001 | priority | security | Vulnerabilit | The CLI | | .org/pypi :: | | | | y found | tools in | | rdflib :: | | | | | RDFLib 4.2.2 | | 4.2.2 | | | | | can load | | | | | | | Python | | | | | | | modules from | | | | | | | the current | | | | | | | working | | | | | | | directory, | | | | | | | allowing | | | | | | | code | | | | | | | injection, | | | | | | | because | | | | | | | \"python -m\" | | | | | | | looks in | | | | | | | this | | | | | | | directory, | | | | | | | as | | | | | | | demonstrated | | | | | | | by rdf2dot. | +--------------+-----------+----------+----------+--------------+--------------+ You can run specific reports by listing them. In the command below I just ask for the report from the safety reporter: valiant report rdflib 4.2.2 safety -s For multiple reports, just use a comma separator: valiant report rdflib 4.2.2 safety,basic -s You can see the list of available reports by running the valiant config command.","title":"Review a dependency"},{"location":"walkthrough/#json-reports","text":"You can get a copy of the report in JSON by setting the output: valiant report rdflib 4.2.2 -o json You can also produce a JSON-based findings report: valiant report rdflib 4.2.2 -s -o json As we saw in the test output examples, you can limit the reports you want: valiant report rdflib 4.2.2 safety -s -o json As a hint, it can be useful to pass the result to the handy jq tool : poetry run valiant report flask 1.1.1 -o json | jq This will give you something like: [ { \"id\": \"SAFETY001\", \"coordinates\": { \"name\": \"rdflib\", \"version\": \"4.2.2\", \"repository_url\": \"https://pypi.org/pypi\" }, \"level\": \"priority\", \"category\": \"security\", \"title\": \"Vulnerability found\", \"message\": \"The CLI tools in RDFLib 4.2.2 can load Python modules from the current working directory, allowing code injection, because \\\"python -m\\\" looks in this directory, as demonstrated by rdf2dot.\", \"data\": { \"name\": \"rdflib\", \"spec\": \"==4.2.2\", \"version\": \"4.2.2\", \"advisory\": \"The CLI tools in RDFLib 4.2.2 can load Python modules from the current working directory, allowing code injection, because \\\"python -m\\\" looks in this directory, as demonstrated by rdf2dot.\", \"vuln_id\": \"36882\" }, \"url\": \"https://github.com/pyupio/safety-db\" } ]","title":"JSON reports"},{"location":"walkthrough/#auditing-a-project","text":"An audit is essentially a review of multiple dependencies. Valiant uses a requirements file as input. Importantly, the packages listed in the requirements file must be pinned to a specific version. The example below illustrates how this looks: click==7.1.1 flask==1.1.1 isodate==0.6.0 itsdangerous==1.1.0 jinja2==2.11.1 markupsafe==1.1.1 numpy==1.18.2 pandas==1.0.3 pyparsing==2.4.6 python-dateutil==2.8.1 pytz==2019.3 rdflib==4.2.2 six==1.14.0 werkzeug==1.0.0 Thankfully, Poetry's export command makes this easy and we'll use this in the walk-through. Let's go through the steps of creating a small project and running an audit. First of all, create a directory for the test project: # Setup the project mkdir test-valiant cd test-valiant Make sure you're running Python 3.8 (or greater). I use pyenv and this makes it easy: pyenv local 3.8.2 Better still, create a virtualenv - see the instructions at the beginning of this page. Now we set up the Poetry project and add some dependencies: pip install poetry poetry init -n # Add some dependencies poetry add flask rdflib pandas requests It's now possible to export the pinned requirements file: # Export the requirements file poetry export --without-hashes --format requirements.txt --output requirements.txt You can now run an audit of your dependencies with: valiant audit requirements.txt This will pump out a lot of information for you to sift through! It's basically a set of reports - much like running the valiant report command for each package. If you just want to view the findings across all reports: valiant audit requirements.txt -s","title":"Auditing a project"},{"location":"walkthrough/#json-audit-reports","text":"As with the one-off report, you can get the audit in JSON format: poetry run valiant audit requirements.txt -o json The findings-only listing is also available: poetry run valiant audit requirements.txt -s -o json","title":"JSON audit reports"},{"location":"demo/opa/","text":"Valiant and the Open Policy Agent Valiant is an auditing tool for Python projects. It aims to provide an easy method for gathering information about project dependencies so as to help developers determine potential risks that dependencies may present. Example risks include licensing issues, known vulnerabilities and project sustainability. The Open Policy Agent (OPA) provides a toolset for defining policies and comparing input data against the policies. In this demo I'll demonstrate how to define OPA policies and use them to review data from Valiant. This helps determine if a project meets governance requirements. I'm new to OPA so please let me know if you feel the policies could be improved. Get started with Valiant Valiant is a Python package available on PyPi . Installing Valiant requires Python 3.8 and the standard pip command: pip install -U valiant Once installed, check the details with: valiant about Version 0.2.1 or above will be fine for this article. Say you wanted to check the details for the Flask package : valiant report flask 1.1.1 That displays a human-readable output but for OPA we'll need JSON: valiant report flask 1.1.1 -o json It's more likely that you'll want to check all of a project's dependencies against your policies. I'll use Poetry to initialise a project and add some dependencies: pip install poetry poetry new demo_project cd demo_project poetry add flask==1.1.1 poetry add insecure-package==0.1.0 You'll be able to see the project configuration in the pyproject.toml file. To see the non-development dependencies, try poetry show --no-dev . For a nice tree view, try poetry show --no-dev --tree and you'll get something similar to the output below: flask 1.1.1 A simple framework for building complex web applications. \u251c\u2500\u2500 click >=5.1 \u251c\u2500\u2500 itsdangerous >=0.24 \u251c\u2500\u2500 jinja2 >=2.10.1 \u2502 \u2514\u2500\u2500 markupsafe >=0.23 \u2514\u2500\u2500 werkzeug >=0.15 insecure-package 0.1.0 Insecure Package, don't use it The insecure-package is a demo package that the safety scanner uses as a demonstrator package - it is safe to use. Now that we have a (small) project set up, we can run Valiant reporting for the dependencies: # Export the dependencies to a requirements.txt file: poetry export --format requirements.txt --output requirements.txt --without-hashes # Display a list of findings poetry run valiant audit requirements.txt -s The output will be a table of findings similar to the one below: +--------------+-----------+----------+----------+--------------+--------------+ | Package | ID | Level | Category | Title | Message | | Coordinates | | | | | | +==============+===========+==========+==========+==============+==============+ | https://pypi | SPDX001 | info | license | SPDX License | BSD-3-Clause | | .org/pypi :: | | | | found | | | click :: | | | | | | | 7.1.2 | | | | | | +--------------+-----------+----------+----------+--------------+--------------+ | https://pypi | SPDX001 | info | license | SPDX License | BSD-3-Clause | | .org/pypi :: | | | | found | | | Flask :: | | | | | | | 1.1.1 | | | | | | +--------------+-----------+----------+----------+--------------+--------------+ | https://pypi | BASIC003 | warning | project | No link to | The project | | .org/pypi :: | | | | codebase | doesn't | | insecure- | | | | | provide a | | package :: | | | | | link to its | | 0.1.0 | | | | | codebase. | +--------------+-----------+----------+----------+--------------+--------------+ Whilst a table is handy for us to read, we'll need JSON to feed into OPA: # Audit the requirements with JSON output: valiant audit requirements.txt --out json>valiant_audit.json Hint: use the jq tool to view the audit data: cat valiant_audit.json |jq You can find a copy of the audit output in the project repository under docs/demo/opa/valiant_audit.json . Now that we have the basics of Valiant sorted out, let's take OPA for a quick spin. Get started with OPA Through this article I'll use a local copy of OPA . You could also use an OPA docker image : docker pull docker.io/openpolicyagent/opa The code for used in this article is located in the docs/demo/opa directory of the Valiant GitHub project . I'll provide most of the code in this article so you don't need to get a copy of the repository (but you're always welcome to do so). The Rego playground is a useful tool for trying out policy files. You can copy the .rego code from this article and try it out in the playground. The OPA extension for Visual Studio Code is worth trying out if you're using VSCode. A basic policy test OPA policies are defined in a rego file. The code below defines a policy that requires that an MIT license be used: basic.rego: package basic default allow = false allow { input.license == \"MIT\" } Policy testing provides a mechanism for checking that the policy is capturing conditions correctly. The code below provides a basic test suite for our basic policy: basic_test.rego: package basic test_app_allowed { allow with input as {\"name\": \"valiant\", \"license\": \"MIT\"} } test_app_not_allowed { not allow with input as {\"name\": \"my_app\", \"license\": \"BSD-3-Clause\"} } test_app_not_allowed_missing_license { not allow with input as {\"name\": \"my_app\"} } Let's run the tests: ./opa test basic -v The output should appear as follows: data.basic.test_app_allowed: PASS (127.108075ms) data.basic.test_app_not_allowed: PASS (429.647\u00b5s) data.basic.test_app_not_allowed_missing_license: PASS (421.856\u00b5s) -------------------------------------------------------------------------------- PASS: 3/3 Consider an input that provides the correct license: { \"name\": \"test\", \"license\": \"MIT\" } We can check this against the policy using: ./opa eval \\ --data basic/basic.rego \\ --input input/input_1.json \\ --format pretty \\ 'data.basic' The result indicates that the input meets the policy requirement: { \"allow\": true } A different input uses an unacceptable license: { \"name\": \"test2\", \"license\": \"Commercial\" } Running an evaluation against the input: ./opa eval \\ --data basic/basic.rego \\ --input input/input_2.json \\ --format pretty \\ 'data.basic' ... and we see that false is returned and the policy is not met: { \"allow\": false } Test a single package Let's move on and start using real data. This time we want to check if a candidate dependency will meet policy requirements. First of all, produce Valiant reports for a number of packages: valiant report flask 1.1.1 --out json > report/flask.json valiant report django 1.2 --out json > report/django.json valiant report valiant 0.2.1 --out json > report/valiant.json Note: I've used a very old version of Django so as to illustrate security findings. Valiant uses reporting plugins to produce a set of findings for each package. You can quickly view these with valiant report django 1.2 -s or, with the json we produced just before, you can create a summary with: cat report/valiant.json \\ | jq '.reports[].findings[] | {id:.id, package: .coordinates.name, version: .coordinates.version, title: .title, message: .message, data: .data}' So now we have some input data to test, let's create some policies. The policies/dependency.rego file contains all of the policies discussed in this section. First of all, I want to make sure I'm only using packages with a correctly declared licence. The Valiant SPDC reporting plugin returns the SPDX002 finding when the package's licence could not be determined. The check below will note a violation on an SPDX002 finding: violations[pkg] = message { # All packages must have a properly declared license findings := input.reports.spdx.findings[_] findings.id == \"SPDX002\" pkg := concat(\"::\", [findings.coordinates.name, findings.coordinates.version]) message := \"SPDX002: No licence could be determined.\" } Next, I want to make sure that, where a license could be determined ( SPDX001 ), it is an OSI approved license . The following policy will check that a license was found and it is an OSI approved license: violations[pkg] = message { # All packages must have an OSI-approved license findings := input.reports.spdx.findings[_] findings.id == \"SPDX001\"; findings.data.is_osi_approved != true pkg := concat(\"::\", [findings.coordinates.name, findings.coordinates.version]) message := \"An OSI-approved licence is required.\" } Valiant's Safety report provider uses the Safety package to determine any known vulnerabilities for a package. This check just looks for any SAFETY001 findings: violations[pkg] = message { # Any findings from the safety report needs to be raised findings := input.reports.safety.findings[_] findings.id == \"SAFETY001\" pkg := concat(\"::\", [findings.coordinates.name, findings.coordinates.version]) message := concat(\": \", [findings.id, findings.message]) } Finally I want to check for packages that the Basic report provider determines as not production ready. The BASIC005 finding flags packages with a development status between 1 and 4 (refer to the classifiers ) and BASIC006 flags packages marked as inactive. violations[pkg] = message { # Packages not marked as production-ready not_mature := {\"BASIC005\", \"BASIC006\"} findings := input.reports.basic.findings[_] not_mature[findings.id] pkg := concat(\"::\", [findings.coordinates.name, findings.coordinates.version]) message := concat(\": \", [findings.id, findings.message]) } The allow rule will return true if no violations were found: allow = true { count(violations) == 0 } Policy check We can check the Flask report from Valiant against the policy: ./opa eval --data policies \\ --input report/flask.json \\ --format pretty \\ 'data.valiant.demo.dependency.allow' The output is true , indicating that the allow policy was met. That's handy for a visual check but OPA can give us something a bit more tangible: ./opa eval --data policies \\ --input report/flask.json \\ --format pretty \\ --fail-defined 'data.valiant.demo.dependency.violations[pkg]' The resulting output of undefined indicates that there were no violations. By using the --fail-defined parameter, the exit code is set based on if any result was found. Calling echo $? displays 0 , indicating that the flask.json data does not raise any policy violations. Trying the evaluation against the valiant.json report will yield a policy violation: ./opa eval --data policies \\ --input report/valiant.json \\ --format pretty \\ --fail-defined 'data.valiant.demo.dependency.violations[pkg]' echo $? The exit value ( $? ) of 1 indicates that there were violations and the table displayed by OPA describes the issue: +------------------+----------------------------------------------+ | pkg | data.valiant.demo.dependency.violations[pkg] | +------------------+----------------------------------------------+ | \"valiant::0.2.1\" | \"BASIC005: The package is | | | marked as '1 - Planning'\" | +------------------+----------------------------------------------+ The report from the very old Django version will yield even more to be concerned about: ./opa eval --data policies \\ --input report/django.json \\ --format pretty \\ --fail-defined 'data.valiant.demo.dependency.violations[pkg]' There are a lot of violations coming from that report! Here's an excerpt: +---------------+----------------------------------------------+ | pkg | data.valiant.demo.dependency.violations[pkg] | +---------------+----------------------------------------------+ | \"Django::1.2\" | \"SPDX002: No licence could be | | | determined.\" | | \"Django::1.2\" | \"SAFETY001: Django before | | | 1.11.27, 2.x before 2.2.9, | | | and 3.x before 3.0.1 allows | | | account takeover. A suitably | | | crafted email address (that | | | is equal to an existing user's | | | email address after case | | | transformation of Unicode | | | characters) would allow an | | | attacker to be sent a password | | | reset token for the matched | | | user account. (One mitigation | | | in the new releases is to send | | | password reset tokens only | | | to the registered user email | | | address.) See CVE-2019-19844.\" | | \"Django::1.2\" | \"SAFETY001: Cross-site | | | scripting (XSS) vulnerability | | | in Django 1.2.x before 1.2.2 | | | allows remote attackers to | | | inject arbitrary web script or | | | HTML via a csrfmiddlewaretoken | | | (aka csrf_token) cookie.\" | Auditing a project It's more likely that we'll want to check the full set of project dependencies against our policies. This would be handy as part of a CI/CD pipeline as we could block non-compliant projects from being deployed. Recall that earlier I used poetry to generate the dependency list and passed this to valiant produce an audit report: # Export the dependencies to a requirements.txt file: poetry export --format requirements.txt --output requirements.txt --without-hashes # Run an audit and output JSON: valiant audit requirements.txt --out json>valiant_audit.json The resulting JSON is an array of reports (1 per package) and each report will have 0 or more findings garnered from the various reporting plugins we've used. This is a different structure to the single-package report covered in the last section so the policies will need some changes. The audit-policies/main.rego policy file defines a suite of checks to determine aspects of the Valiant audit report that breach policy. It's quite similar to the policy described earlier - just with some slightly different checks: package valiant.demo default allow = false violations[pkg] = message { # Packages not marked as production-ready not_mature := {\"BASIC005\", \"BASIC006\"} findings := input[_].reports.basic.findings[_] not_mature[findings.id] pkg := concat(\"::\", [findings.coordinates.name, findings.coordinates.version]) message := concat(\": \", [findings.id, findings.message]) } violations[pkg] = message { # Only allow specifically approved licences permitted_licenses := {\"BSD-3-Clause\", \"MIT\"} findings := input[_].reports.spdx.findings[_] findings.id == \"SPDX001\" not permitted_licenses[findings.message] pkg := concat(\"::\", [findings.coordinates.name, findings.coordinates.version]) message := concat(\": \", [findings.id, findings.message]) } violations[pkg] = message { # All packages must have a properly declared license findings := input[_].reports.spdx.findings[_] findings.id == \"SPDX002\" pkg := concat(\"::\", [findings.coordinates.name, findings.coordinates.version]) message := concat(\": \", [findings.id, findings.message]) } violations[pkg] = message { # Any findings from the safety report needs to be raised findings := input[_].reports.safety.findings[_] findings.id == \"SAFETY001\" pkg := concat(\"::\", [findings.coordinates.name, findings.coordinates.version]) message := concat(\": \", [findings.id, findings.message]) } allow = true { count(violations) == 0 } Note: a small test suite is provided and can be run with ./opa test policies -v . Policy check Now that we have the policy defined and the input data ready, we can perform an evaluation: ./opa eval --data policies/ \\ --input valiant_audit.json \\ --format pretty \\ --fail-defined 'data.valiant.demo.audit.violations[pkg]' +---------------------------+-----------------------------------+ | pkg | data.valiant.demo.violations[pkg] | +---------------------------+-----------------------------------+ | \"insecure-package::0.1.0\" | \"BASIC005: The package is | | | marked as '2 - Pre-Alpha'\" | | \"insecure-package::0.1.0\" | \"SPDX002: Could not map | | | licence MIT license to an SPDX | | | license\" | | \"itsdangerous::1.1.0\" | \"SPDX002: Could not map | | | licence BSD to an SPDX | | | license\" | | \"insecure-package::0.1.0\" | \"SAFETY001: This is an | | | insecure package with lots | | | of exploitable security | | | vulnerabilities.\" | +---------------------------+-----------------------------------+ As an aside, you may note that insecure-package is reported as not having an SPDX licence. Whilst the Pypi metadata for the package does provide \"license\": \"MIT license\" , the reporting just looks for MIT and it's the additional license that causes a failed match. Perhaps as Valiant matures this matching will improve. Again, by using the --fail-defined 'data.valiant.demo.violations[pkg]' parameter we can then check the exit code ( echo $? ) and see the command returned 1 . The policy check could be wrapped in a script or some other construct in a continuous integration process that causes the build to fail. Using this approach provides an easy policy layer to the CI/CD process and can prevent deployments that don't meet policy guidelines. Conclusion This article has outlined a method for defining policies for a project and using Valiant to supply data for policy validation. This light-weight process can be used by a developer as part of their daily routine and pre-commit checks. In a broader usage model, OPA could be run as a central policy server and used by CI/CD pipelines to ensure that only compliant codebases are able to be deployed. The Valiant project is very young but it supports plugins for gathering information about Python dependencies. You can readily add reports that run under Valiant and then check that (meta)data using OPA. Ultimately, the goal is to recognise/reduce risk in your software project's supply chain. This contributes to teams ensuring sustainability in their projects. Further reading: OPA Documentation Policy-driven continuous integration with Open Policy Agent Kubernetes Podcast: Open Policy Agent, with Tim Hinrichs and Torin Sandall","title":"Valiant and Open Policy Agent"},{"location":"demo/opa/#valiant-and-the-open-policy-agent","text":"Valiant is an auditing tool for Python projects. It aims to provide an easy method for gathering information about project dependencies so as to help developers determine potential risks that dependencies may present. Example risks include licensing issues, known vulnerabilities and project sustainability. The Open Policy Agent (OPA) provides a toolset for defining policies and comparing input data against the policies. In this demo I'll demonstrate how to define OPA policies and use them to review data from Valiant. This helps determine if a project meets governance requirements. I'm new to OPA so please let me know if you feel the policies could be improved.","title":"Valiant and the Open Policy Agent"},{"location":"demo/opa/#get-started-with-valiant","text":"Valiant is a Python package available on PyPi . Installing Valiant requires Python 3.8 and the standard pip command: pip install -U valiant Once installed, check the details with: valiant about Version 0.2.1 or above will be fine for this article. Say you wanted to check the details for the Flask package : valiant report flask 1.1.1 That displays a human-readable output but for OPA we'll need JSON: valiant report flask 1.1.1 -o json It's more likely that you'll want to check all of a project's dependencies against your policies. I'll use Poetry to initialise a project and add some dependencies: pip install poetry poetry new demo_project cd demo_project poetry add flask==1.1.1 poetry add insecure-package==0.1.0 You'll be able to see the project configuration in the pyproject.toml file. To see the non-development dependencies, try poetry show --no-dev . For a nice tree view, try poetry show --no-dev --tree and you'll get something similar to the output below: flask 1.1.1 A simple framework for building complex web applications. \u251c\u2500\u2500 click >=5.1 \u251c\u2500\u2500 itsdangerous >=0.24 \u251c\u2500\u2500 jinja2 >=2.10.1 \u2502 \u2514\u2500\u2500 markupsafe >=0.23 \u2514\u2500\u2500 werkzeug >=0.15 insecure-package 0.1.0 Insecure Package, don't use it The insecure-package is a demo package that the safety scanner uses as a demonstrator package - it is safe to use. Now that we have a (small) project set up, we can run Valiant reporting for the dependencies: # Export the dependencies to a requirements.txt file: poetry export --format requirements.txt --output requirements.txt --without-hashes # Display a list of findings poetry run valiant audit requirements.txt -s The output will be a table of findings similar to the one below: +--------------+-----------+----------+----------+--------------+--------------+ | Package | ID | Level | Category | Title | Message | | Coordinates | | | | | | +==============+===========+==========+==========+==============+==============+ | https://pypi | SPDX001 | info | license | SPDX License | BSD-3-Clause | | .org/pypi :: | | | | found | | | click :: | | | | | | | 7.1.2 | | | | | | +--------------+-----------+----------+----------+--------------+--------------+ | https://pypi | SPDX001 | info | license | SPDX License | BSD-3-Clause | | .org/pypi :: | | | | found | | | Flask :: | | | | | | | 1.1.1 | | | | | | +--------------+-----------+----------+----------+--------------+--------------+ | https://pypi | BASIC003 | warning | project | No link to | The project | | .org/pypi :: | | | | codebase | doesn't | | insecure- | | | | | provide a | | package :: | | | | | link to its | | 0.1.0 | | | | | codebase. | +--------------+-----------+----------+----------+--------------+--------------+ Whilst a table is handy for us to read, we'll need JSON to feed into OPA: # Audit the requirements with JSON output: valiant audit requirements.txt --out json>valiant_audit.json Hint: use the jq tool to view the audit data: cat valiant_audit.json |jq You can find a copy of the audit output in the project repository under docs/demo/opa/valiant_audit.json . Now that we have the basics of Valiant sorted out, let's take OPA for a quick spin.","title":"Get started with Valiant"},{"location":"demo/opa/#get-started-with-opa","text":"Through this article I'll use a local copy of OPA . You could also use an OPA docker image : docker pull docker.io/openpolicyagent/opa The code for used in this article is located in the docs/demo/opa directory of the Valiant GitHub project . I'll provide most of the code in this article so you don't need to get a copy of the repository (but you're always welcome to do so). The Rego playground is a useful tool for trying out policy files. You can copy the .rego code from this article and try it out in the playground. The OPA extension for Visual Studio Code is worth trying out if you're using VSCode.","title":"Get started with OPA"},{"location":"demo/opa/#a-basic-policy-test","text":"OPA policies are defined in a rego file. The code below defines a policy that requires that an MIT license be used: basic.rego: package basic default allow = false allow { input.license == \"MIT\" } Policy testing provides a mechanism for checking that the policy is capturing conditions correctly. The code below provides a basic test suite for our basic policy: basic_test.rego: package basic test_app_allowed { allow with input as {\"name\": \"valiant\", \"license\": \"MIT\"} } test_app_not_allowed { not allow with input as {\"name\": \"my_app\", \"license\": \"BSD-3-Clause\"} } test_app_not_allowed_missing_license { not allow with input as {\"name\": \"my_app\"} } Let's run the tests: ./opa test basic -v The output should appear as follows: data.basic.test_app_allowed: PASS (127.108075ms) data.basic.test_app_not_allowed: PASS (429.647\u00b5s) data.basic.test_app_not_allowed_missing_license: PASS (421.856\u00b5s) -------------------------------------------------------------------------------- PASS: 3/3 Consider an input that provides the correct license: { \"name\": \"test\", \"license\": \"MIT\" } We can check this against the policy using: ./opa eval \\ --data basic/basic.rego \\ --input input/input_1.json \\ --format pretty \\ 'data.basic' The result indicates that the input meets the policy requirement: { \"allow\": true } A different input uses an unacceptable license: { \"name\": \"test2\", \"license\": \"Commercial\" } Running an evaluation against the input: ./opa eval \\ --data basic/basic.rego \\ --input input/input_2.json \\ --format pretty \\ 'data.basic' ... and we see that false is returned and the policy is not met: { \"allow\": false }","title":"A basic policy test"},{"location":"demo/opa/#test-a-single-package","text":"Let's move on and start using real data. This time we want to check if a candidate dependency will meet policy requirements. First of all, produce Valiant reports for a number of packages: valiant report flask 1.1.1 --out json > report/flask.json valiant report django 1.2 --out json > report/django.json valiant report valiant 0.2.1 --out json > report/valiant.json Note: I've used a very old version of Django so as to illustrate security findings. Valiant uses reporting plugins to produce a set of findings for each package. You can quickly view these with valiant report django 1.2 -s or, with the json we produced just before, you can create a summary with: cat report/valiant.json \\ | jq '.reports[].findings[] | {id:.id, package: .coordinates.name, version: .coordinates.version, title: .title, message: .message, data: .data}' So now we have some input data to test, let's create some policies. The policies/dependency.rego file contains all of the policies discussed in this section. First of all, I want to make sure I'm only using packages with a correctly declared licence. The Valiant SPDC reporting plugin returns the SPDX002 finding when the package's licence could not be determined. The check below will note a violation on an SPDX002 finding: violations[pkg] = message { # All packages must have a properly declared license findings := input.reports.spdx.findings[_] findings.id == \"SPDX002\" pkg := concat(\"::\", [findings.coordinates.name, findings.coordinates.version]) message := \"SPDX002: No licence could be determined.\" } Next, I want to make sure that, where a license could be determined ( SPDX001 ), it is an OSI approved license . The following policy will check that a license was found and it is an OSI approved license: violations[pkg] = message { # All packages must have an OSI-approved license findings := input.reports.spdx.findings[_] findings.id == \"SPDX001\"; findings.data.is_osi_approved != true pkg := concat(\"::\", [findings.coordinates.name, findings.coordinates.version]) message := \"An OSI-approved licence is required.\" } Valiant's Safety report provider uses the Safety package to determine any known vulnerabilities for a package. This check just looks for any SAFETY001 findings: violations[pkg] = message { # Any findings from the safety report needs to be raised findings := input.reports.safety.findings[_] findings.id == \"SAFETY001\" pkg := concat(\"::\", [findings.coordinates.name, findings.coordinates.version]) message := concat(\": \", [findings.id, findings.message]) } Finally I want to check for packages that the Basic report provider determines as not production ready. The BASIC005 finding flags packages with a development status between 1 and 4 (refer to the classifiers ) and BASIC006 flags packages marked as inactive. violations[pkg] = message { # Packages not marked as production-ready not_mature := {\"BASIC005\", \"BASIC006\"} findings := input.reports.basic.findings[_] not_mature[findings.id] pkg := concat(\"::\", [findings.coordinates.name, findings.coordinates.version]) message := concat(\": \", [findings.id, findings.message]) } The allow rule will return true if no violations were found: allow = true { count(violations) == 0 }","title":"Test a single package"},{"location":"demo/opa/#policy-check","text":"We can check the Flask report from Valiant against the policy: ./opa eval --data policies \\ --input report/flask.json \\ --format pretty \\ 'data.valiant.demo.dependency.allow' The output is true , indicating that the allow policy was met. That's handy for a visual check but OPA can give us something a bit more tangible: ./opa eval --data policies \\ --input report/flask.json \\ --format pretty \\ --fail-defined 'data.valiant.demo.dependency.violations[pkg]' The resulting output of undefined indicates that there were no violations. By using the --fail-defined parameter, the exit code is set based on if any result was found. Calling echo $? displays 0 , indicating that the flask.json data does not raise any policy violations. Trying the evaluation against the valiant.json report will yield a policy violation: ./opa eval --data policies \\ --input report/valiant.json \\ --format pretty \\ --fail-defined 'data.valiant.demo.dependency.violations[pkg]' echo $? The exit value ( $? ) of 1 indicates that there were violations and the table displayed by OPA describes the issue: +------------------+----------------------------------------------+ | pkg | data.valiant.demo.dependency.violations[pkg] | +------------------+----------------------------------------------+ | \"valiant::0.2.1\" | \"BASIC005: The package is | | | marked as '1 - Planning'\" | +------------------+----------------------------------------------+ The report from the very old Django version will yield even more to be concerned about: ./opa eval --data policies \\ --input report/django.json \\ --format pretty \\ --fail-defined 'data.valiant.demo.dependency.violations[pkg]' There are a lot of violations coming from that report! Here's an excerpt: +---------------+----------------------------------------------+ | pkg | data.valiant.demo.dependency.violations[pkg] | +---------------+----------------------------------------------+ | \"Django::1.2\" | \"SPDX002: No licence could be | | | determined.\" | | \"Django::1.2\" | \"SAFETY001: Django before | | | 1.11.27, 2.x before 2.2.9, | | | and 3.x before 3.0.1 allows | | | account takeover. A suitably | | | crafted email address (that | | | is equal to an existing user's | | | email address after case | | | transformation of Unicode | | | characters) would allow an | | | attacker to be sent a password | | | reset token for the matched | | | user account. (One mitigation | | | in the new releases is to send | | | password reset tokens only | | | to the registered user email | | | address.) See CVE-2019-19844.\" | | \"Django::1.2\" | \"SAFETY001: Cross-site | | | scripting (XSS) vulnerability | | | in Django 1.2.x before 1.2.2 | | | allows remote attackers to | | | inject arbitrary web script or | | | HTML via a csrfmiddlewaretoken | | | (aka csrf_token) cookie.\" |","title":"Policy check"},{"location":"demo/opa/#auditing-a-project","text":"It's more likely that we'll want to check the full set of project dependencies against our policies. This would be handy as part of a CI/CD pipeline as we could block non-compliant projects from being deployed. Recall that earlier I used poetry to generate the dependency list and passed this to valiant produce an audit report: # Export the dependencies to a requirements.txt file: poetry export --format requirements.txt --output requirements.txt --without-hashes # Run an audit and output JSON: valiant audit requirements.txt --out json>valiant_audit.json The resulting JSON is an array of reports (1 per package) and each report will have 0 or more findings garnered from the various reporting plugins we've used. This is a different structure to the single-package report covered in the last section so the policies will need some changes. The audit-policies/main.rego policy file defines a suite of checks to determine aspects of the Valiant audit report that breach policy. It's quite similar to the policy described earlier - just with some slightly different checks: package valiant.demo default allow = false violations[pkg] = message { # Packages not marked as production-ready not_mature := {\"BASIC005\", \"BASIC006\"} findings := input[_].reports.basic.findings[_] not_mature[findings.id] pkg := concat(\"::\", [findings.coordinates.name, findings.coordinates.version]) message := concat(\": \", [findings.id, findings.message]) } violations[pkg] = message { # Only allow specifically approved licences permitted_licenses := {\"BSD-3-Clause\", \"MIT\"} findings := input[_].reports.spdx.findings[_] findings.id == \"SPDX001\" not permitted_licenses[findings.message] pkg := concat(\"::\", [findings.coordinates.name, findings.coordinates.version]) message := concat(\": \", [findings.id, findings.message]) } violations[pkg] = message { # All packages must have a properly declared license findings := input[_].reports.spdx.findings[_] findings.id == \"SPDX002\" pkg := concat(\"::\", [findings.coordinates.name, findings.coordinates.version]) message := concat(\": \", [findings.id, findings.message]) } violations[pkg] = message { # Any findings from the safety report needs to be raised findings := input[_].reports.safety.findings[_] findings.id == \"SAFETY001\" pkg := concat(\"::\", [findings.coordinates.name, findings.coordinates.version]) message := concat(\": \", [findings.id, findings.message]) } allow = true { count(violations) == 0 } Note: a small test suite is provided and can be run with ./opa test policies -v .","title":"Auditing a project"},{"location":"demo/opa/#policy-check_1","text":"Now that we have the policy defined and the input data ready, we can perform an evaluation: ./opa eval --data policies/ \\ --input valiant_audit.json \\ --format pretty \\ --fail-defined 'data.valiant.demo.audit.violations[pkg]' +---------------------------+-----------------------------------+ | pkg | data.valiant.demo.violations[pkg] | +---------------------------+-----------------------------------+ | \"insecure-package::0.1.0\" | \"BASIC005: The package is | | | marked as '2 - Pre-Alpha'\" | | \"insecure-package::0.1.0\" | \"SPDX002: Could not map | | | licence MIT license to an SPDX | | | license\" | | \"itsdangerous::1.1.0\" | \"SPDX002: Could not map | | | licence BSD to an SPDX | | | license\" | | \"insecure-package::0.1.0\" | \"SAFETY001: This is an | | | insecure package with lots | | | of exploitable security | | | vulnerabilities.\" | +---------------------------+-----------------------------------+ As an aside, you may note that insecure-package is reported as not having an SPDX licence. Whilst the Pypi metadata for the package does provide \"license\": \"MIT license\" , the reporting just looks for MIT and it's the additional license that causes a failed match. Perhaps as Valiant matures this matching will improve. Again, by using the --fail-defined 'data.valiant.demo.violations[pkg]' parameter we can then check the exit code ( echo $? ) and see the command returned 1 . The policy check could be wrapped in a script or some other construct in a continuous integration process that causes the build to fail. Using this approach provides an easy policy layer to the CI/CD process and can prevent deployments that don't meet policy guidelines.","title":"Policy check"},{"location":"demo/opa/#conclusion","text":"This article has outlined a method for defining policies for a project and using Valiant to supply data for policy validation. This light-weight process can be used by a developer as part of their daily routine and pre-commit checks. In a broader usage model, OPA could be run as a central policy server and used by CI/CD pipelines to ensure that only compliant codebases are able to be deployed. The Valiant project is very young but it supports plugins for gathering information about Python dependencies. You can readily add reports that run under Valiant and then check that (meta)data using OPA. Ultimately, the goal is to recognise/reduce risk in your software project's supply chain. This contributes to teams ensuring sustainability in their projects.","title":"Conclusion"},{"location":"demo/opa/#further-reading","text":"OPA Documentation Policy-driven continuous integration with Open Policy Agent Kubernetes Podcast: Open Policy Agent, with Tim Hinrichs and Torin Sandall","title":"Further reading:"}]}